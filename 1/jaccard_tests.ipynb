{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f20bf4",
   "metadata": {},
   "source": [
    "\n",
    "    Performs small-scale tests on the dataset using different representations for the vectorizations and \n",
    "    different implementation of the Jaccard distances.\n",
    "    1. Default CountVectorizer() and default \"metric='jaccard'\" in knn classifier.\n",
    "    2. One-hot CountVectorizer(binary=True) and custom jaccard metric acting on one-hot vectors.\n",
    "    3. Vocabulary indexing and custom jaccard metric acting on those vectors.\n",
    "    4. TFIDF vectorizer and default \"metric='jaccard'\".\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee0c84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76d8d838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          Id                                        Content_Pre  Target\n",
       "0    227464  netflix come cabl box amazon groceri overlord ...       0\n",
       "1    244074  pharrel iranian presid react tehran happi arre...       0\n",
       "2     60707  wildlif servic seek comment fish wildlif servi...       1\n",
       "3     27883  facebook team story launch fb newswir natur so...       1\n",
       "4    169596  caesar plan us mln new york casino caesar plan...       2\n",
       "..      ...                                                ...     ...\n",
       "995  253918  miley cyru maserati quattroport stolen miley c...       0\n",
       "996  261459  charg paul simon edi brickel drop two month ch...       0\n",
       "997  148745  rpt lenovo aim sell mln smartphon tablet come ...       2\n",
       "998  177032  settlement big bank send right messag settleme...       2\n",
       "999  134656  wall street stock close mostli higher earn app...       2\n",
       "\n",
       "[1000 rows x 3 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train_test = 1000\n",
    "split = 0.1\n",
    "\n",
    "df = pd.read_csv(r\"/home/vkalekis/Documents/bigdata/dataframes/df1/train_concat.csv\", encoding=\"utf-8\", nrows=len_train_test)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba58bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, -2].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df.iloc[:, -2].values, \n",
    "                                    df.iloc[:, -1].values, \n",
    "                                    test_size=split,\n",
    "                                    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "256b45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (900,) (900,) (100,) (100,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes: {X_train.shape} {y_train.shape} {X_test.shape} {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b1a4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 17219)\n",
      "(100, 17219)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 1-------------------------------------------------------------\n",
    "# Count Vectorizer - Generates vocabulary of words in train set.\n",
    "# Creates vectors for each entry in train+test set \n",
    "# which contain the count of each word in the vocabulary in the entry.\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_cv1 = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_cv1 = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "print(X_train_cv1.shape)\n",
    "print(X_test_cv1.shape)\n",
    "\n",
    "print(X_train_cv1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918d1d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 17219)\n",
      "(100, 17219)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 2-------------------------------------------------------------\n",
    "# One-hot Count Vectorizer - Generates vocabulary of words in train set.\n",
    "# Creates one hot representation of each vector in train+test set.\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_cv2 = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_cv2 = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "print(X_train_cv2.shape)\n",
    "print(X_test_cv2.shape)\n",
    "\n",
    "print(X_train_cv2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a93123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 2084)\n",
      "900\n",
      "100\n",
      "[2590   20   14 ...    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 3-----------------------------------------------------------\n",
    "# Vocabulary indexing \n",
    "# Each word in every document the train+test set is given\n",
    "# its index in the vocabulary of the train set.\n",
    "# We use the keras vectorizer in order to fit only on the train set and \n",
    "# not in both, which would be the case if we used the sklearn one.\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_temp = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_temp = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "pad1 = len(max(X_train_temp, key=len))\n",
    "pad2 = len(max(X_test_temp, key=len))\n",
    "\n",
    "maxpad = max(pad1, pad2)\n",
    "\n",
    "X_train_voc = keras.preprocessing.sequence.pad_sequences(X_train_temp, padding='post', maxlen=maxpad)\n",
    "X_test_voc = keras.preprocessing.sequence.pad_sequences(X_test_temp, padding='post', maxlen=maxpad)\n",
    "\n",
    "\n",
    "print(X_train_voc.shape)\n",
    "print(len(X_train_voc))\n",
    "print(len(X_test_voc))\n",
    "\n",
    "print(X_train_voc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42c7d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 17219)\n",
      "(100, 17219)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 4-------------------------------------------------\n",
    "# Tfidf Vectorizer\n",
    "# Generates term frequency inverse document frequency for each word \n",
    "# in every entry in train and test set.\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)\n",
    "\n",
    "print(X_train_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75625c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_binary(x,y):\n",
    "    \"\"\"\n",
    "        Jaccard Similarity between two binary vectors (used in one-hot vectorization)\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(x, y)\n",
    "    union = np.logical_or(x, y)\n",
    "    similarity = intersection.sum() / float(union.sum())\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24e09a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    \"\"\"\n",
    "        Jaccard similarity between two vectors.\n",
    "    \"\"\"\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8092d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_binary(x, y):\n",
    "    \"\"\"\n",
    "        Jaccard distance using binary Jaccard similarity.\n",
    "    \"\"\"\n",
    "    return 1-jaccard_binary(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edc6dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(x, y):\n",
    "    \"\"\"\n",
    "        Jaccard distance using Jaccard similarity.\n",
    "    \"\"\"\n",
    "    return 1-jaccard_similarity(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6f68a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKnn(choice, X_train, y_train, X_test, y_test):\n",
    "    error = []\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    if choice == 0:\n",
    "        # Default Jaccard distance.\n",
    "        knn = KNeighborsClassifier(n_jobs=1, n_neighbors=5, metric='jaccard')\n",
    "    elif choice == 1:\n",
    "        # Custom Jaccard distance for binary / one-hot vectors.\n",
    "        knn = KNeighborsClassifier(n_jobs=1, n_neighbors=5, metric=jaccard_distance_binary)\n",
    "    elif choice == 2:\n",
    "        # Custom Jaccard distance.\n",
    "        knn = KNeighborsClassifier(n_jobs=1, n_neighbors=5, metric=jaccard_distance)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    predicted = knn.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, predicted)\n",
    "\n",
    "    t2 = time.time()\n",
    "    \n",
    "    return acc, (t2-t1)/60.0, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89557d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkalekis/.local/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1870: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Test 1 - Vectorization using CountVectorizer and default Jaccard distance.\n",
    "acc_1, time_1, pred_1 = runKnn(0, X_train_cv1, y_train, X_test_cv1, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ab68215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2 - One-hot Vectorization using CountVectorizer and custom Jaccard binary distance.\n",
    "acc_2, time_2, pred_2 = runKnn(1, X_train_cv2, y_train, X_test_cv2, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1249fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 - Vocabulary indexing and custom Jaccard distance.\n",
    "acc_3, time_3, pred_3 = runKnn(2, X_train_voc, y_train, X_test_voc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c83e59ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkalekis/.local/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1870: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Test 4 - Tfidf representation and default Jaccard distance.\n",
    "acc_4, time_4, pred_4 = runKnn(0, X_train_tfidf, y_train, \n",
    "                                   X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ad84b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81   0.008332\n",
      "0.81   0.102978\n",
      "0.82   0.510911\n",
      "0.81   0.008144\n"
     ]
    }
   ],
   "source": [
    "print(f\"{acc_1}   {time_1:.6f}\")\n",
    "print(f\"{acc_2}   {time_2:.6f}\")\n",
    "print(f\"{acc_3}   {time_3:.6f}\")\n",
    "print(f\"{acc_4}   {time_4:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
